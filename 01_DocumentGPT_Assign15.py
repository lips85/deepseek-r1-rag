import os
import streamlit as st

from langchain.chat_models.openai import ChatOpenAI
from langchain.embeddings import OpenAIEmbeddings
from langchain.document_loaders.unstructured import UnstructuredFileLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings.cache import CacheBackedEmbeddings
from langchain.vectorstores.faiss import FAISS
from langchain.storage import LocalFileStore
from langchain.prompts import ChatPromptTemplate
from langchain.schema.runnable import RunnablePassthrough, RunnableLambda


# íŒŒì¼ ë¶„ë¦¬ (í•¨ìˆ˜ë“¤)
from utils.functions.chat import ChatMemory, ChatCallbackHandler

# Streamlit í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="DocumentGPT",
    page_icon="ğŸ“ƒ",
    layout="wide",
)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
for key, default in [
    ("messages", []),
    ("api_key", None),
    ("api_key_check", False),
    ("openai_model", "ì„ íƒí•´ì£¼ì„¸ìš”"),
    ("openai_model_check", False),
    ("file_check", False),
]:
    if key not in st.session_state:
        st.session_state[key] = default


# í˜ì´ì§€ ì œëª© ë° ì„¤ëª…
st.title("DocumentGPT")

if not (
    st.session_state["api_key_check"]
    and st.session_state["openai_model_check"]
    and st.session_state["file_check"]
):
    st.markdown(
        """
        ì•ˆë…•í•˜ì„¸ìš”! ì´ í˜ì´ì§€ëŠ” ë¬¸ì„œë¥¼ ì½ì–´ì£¼ëŠ” AIì…ë‹ˆë‹¤.ğŸ˜„ 
        
        ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ê³  ì§ˆë¬¸ì„ í•˜ë©´ ë¬¸ì„œì— ëŒ€í•œ ë‹µë³€ì„ í•´ì¤ë‹ˆë‹¤.
        """
    )

    if not st.session_state["file_check"]:
        st.warning("ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
    else:
        st.success("ğŸ˜„ë¬¸ì„œê°€ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.ğŸ˜„")
    if not st.session_state["api_key_check"]:
        st.warning("API_KEYë¥¼ ë„£ì–´ì£¼ì„¸ìš”.")
    else:
        st.success("ğŸ˜„API_KEYê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.ğŸ˜„")
    if not st.session_state["openai_model_check"]:
        st.warning("ëª¨ë¸ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
    else:
        st.success("ğŸ˜„ëª¨ë¸ì´ ì„ íƒë˜ì—ˆìŠµë‹ˆë‹¤.ğŸ˜„")
else:
    st.success("ğŸ˜„API_KEYì™€ ëª¨ë¸ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.ğŸ˜„")


class FileController:
    # íŒŒì¼ ì„ë² ë”© í•¨ìˆ˜
    @staticmethod
    @st.cache_resource(show_spinner="Embedding file...")
    def embed_file(file):
        os.makedirs("./.cache/files", exist_ok=True)
        file_path = f"./.cache/files/{file.name}"
        with open(file_path, "wb") as f:
            f.write(file.read())

        cache_dir = LocalFileStore(f"./.cache/embeddings/open_ai/{file.name}")
        splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(
            separators=["\n\n", ".", "?", "!"],
            chunk_size=1000,
            chunk_overlap=100,
        )
        loader = UnstructuredFileLoader(file_path)
        docs = loader.load_and_split(text_splitter=splitter)
        embeddings = OpenAIEmbeddings(openai_api_key=st.session_state["api_key"])
        cached_embeddings = CacheBackedEmbeddings.from_bytes_store(
            embeddings, cache_dir
        )
        vectorstore = FAISS.from_documents(docs, cached_embeddings)
        return vectorstore.as_retriever()

    # ë¬¸ì„œ í¬ë§·íŒ… í•¨ìˆ˜
    @staticmethod
    def format_docs(docs):
        return "\n\n".join(document.page_content for document in docs)


# ì‚¬ì´ë“œë°” ì„¤ì •
with st.sidebar:
    st.file_uploader(
        "Upload a .txt .pdf or .docx file",
        type=["pdf", "txt", "docx"],
        key="file",
    )
    if st.session_state["file_check"]:
        st.success("ğŸ˜„ë¬¸ì„œê°€ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.ğŸ˜„")
    else:
        st.warning("ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")

    st.text_input(
        "API_KEY ì…ë ¥",
        placeholder="sk-...",
        key="api_key",
    )

    if st.session_state["api_key_check"]:
        st.success("ğŸ˜„API_KEYê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.ğŸ˜„")
    else:
        st.warning("API_KEYë¥¼ ë„£ì–´ì£¼ì„¸ìš”.")

    st.selectbox(
        "OpenAI Modelì„ ê³¨ë¼ì£¼ì„¸ìš”.",
        key="openai_model",
    )

    if st.session_state["openai_model_check"]:
        st.success("ğŸ˜„ëª¨ë¸ì´ ì„ íƒë˜ì—ˆìŠµë‹ˆë‹¤.ğŸ˜„")
    else:
        st.warning("ëª¨ë¸ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")

    st.write(
        """
        Made by hary.
        
        Github
        https://github.com/lips85/GPT_hary

        streamlit
        https://hary-gpt.streamlit.app/
        """
    )

# ë©”ì¸ ë¡œì§
if (
    st.session_state["api_key_check"]
    and st.session_state["file_check"]
    and st.session_state["openai_model_check"]
):
    llm = ChatOpenAI(
        temperature=0.1,
        streaming=True,
        callbacks=[ChatCallbackHandler()],
        model=st.session_state["openai_model"],
        openai_api_key=st.session_state["api_key"],
    )

    prompt = ChatPromptTemplate.from_messages(
        [
            (
                "system",
                """
                You are an AI that reads documents for me. Please answer based on the document given below. 
                If the information is not in the document, answer the question with "The required information is not in the document." Never make up answers.
                Please answer in the questioner's language 
                
                Context : {context}
                """,
            ),
            ("human", "{question}"),
        ]
    )

    retriever = (
        FileController.embed_file(st.session_state["file"])
        if st.session_state["file_check"]
        else None
    )
    if retriever:
        ChatMemory.send_message("I'm ready! Ask away!", "ai", save=False)
        ChatMemory.paint_history()
        message = st.chat_input("Ask anything about your file...")

        if message:

            ChatMemory.send_message(message, "human")
            chain = (
                {
                    "context": retriever | RunnableLambda(FileController.format_docs),
                    "question": RunnablePassthrough(),
                }
                | prompt
                | llm
            )
            try:
                with st.chat_message("ai"):
                    chain.invoke(message)
            except Exception as e:
                st.error(f"An error occurred: {e}")
                st.warning("OPENAI_API_KEY or ëª¨ë¸ ì„ íƒì„ ë‹¤ì‹œ ì§„í–‰í•´ì£¼ì„¸ìš”.")

    else:
        st.session_state["messages"] = []
